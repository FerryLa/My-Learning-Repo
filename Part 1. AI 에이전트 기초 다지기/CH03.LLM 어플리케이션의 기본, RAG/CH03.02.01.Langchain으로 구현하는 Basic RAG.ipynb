{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¦œğŸ”— LangChain ê¸°ë°˜ RAG ì‹¤ìŠµ (2025ë…„ ìµœì‹ )\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **ìµœì‹  LangChain API**ë¥¼ í™œìš©í•˜ì—¬ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "> ğŸ“¢ **OpenAI RAGì™€ LangChain RAGì˜ ì°¨ì´ì **\n",
        "> \n",
        "> - OpenAIëŠ” `vector_stores` APIë¡œ ê°„ë‹¨í•˜ê²Œ RAGë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆì§€ë§Œ, **ì»¤ìŠ¤í„°ë§ˆì´ì§•ì— ì œí•œ**ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "> - LangChainì€ **Document Loader, Text Splitter, Embedding, Vector Store, Retriever** ë“± ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ëª¨ë“ˆí™”í•˜ì—¬ **ìœ ì—°í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±**ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "> - LangChainì˜ ìµœì‹  `create_agent` APIì™€ `@tool` ë°ì½”ë ˆì´í„°ë¥¼ í™œìš©í•˜ë©´ **Agentic RAG**ë„ ì†ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ ëª©ì°¨\n",
        "\n",
        "1. [í™˜ê²½ ì„¤ì •](#1-í™˜ê²½-ì„¤ì •)\n",
        "2. [RAG ì•„í‚¤í…ì²˜ ì´í•´í•˜ê¸°](#2-rag-ì•„í‚¤í…ì²˜-ì´í•´í•˜ê¸°)\n",
        "3. [ë¬¸ì„œ ë¡œë”© (Document Loading)](#3-ë¬¸ì„œ-ë¡œë”©-document-loading)\n",
        "4. [í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitting)](#4-í…ìŠ¤íŠ¸-ë¶„í• -text-splitting)\n",
        "5. [ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ (Embeddings & Vector Store)](#5-ì„ë² ë”©-ë°-ë²¡í„°-ì €ì¥ì†Œ)\n",
        "6. [2-Step RAG êµ¬í˜„](#6-2-step-rag-êµ¬í˜„)\n",
        "7. [RAG Agent êµ¬í˜„](#7-rag-agent-êµ¬í˜„)\n",
        "8. [ì‹¤ìŠµ: ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸](#8-ì‹¤ìŠµ-ì§ˆì˜ì‘ë‹µ-í…ŒìŠ¤íŠ¸)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. í™˜ê²½ ì„¤ì •\n",
        "\n",
        "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•˜ê³  í™˜ê²½ì„ êµ¬ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "%pip install -qU langchain langchain-openai langchain-community langchain-text-splitters pypdf python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "if os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. RAG ì•„í‚¤í…ì²˜ ì´í•´í•˜ê¸°\n",
        "\n",
        "### RAGì˜ í•µì‹¬ ê°œë…\n",
        "\n",
        "LLMì€ ê°•ë ¥í•˜ì§€ë§Œ ë‘ ê°€ì§€ ì£¼ìš” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "1. **ìœ í•œí•œ ì»¨í…ìŠ¤íŠ¸** - ì „ì²´ ë¬¸ì„œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\n",
        "2. **ì •ì ì¸ ì§€ì‹** - í•™ìŠµ ë°ì´í„°ê°€ íŠ¹ì • ì‹œì ì— ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤\n",
        "\n",
        "RAGëŠ” **ì¿¼ë¦¬ ì‹œì ì— ê´€ë ¨ ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰**í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Langchainì´ ì†Œê°œí•˜ëŠ” RAG ì•„í‚¤í…ì²˜ ì¢…ë¥˜\n",
        "\n",
        "| ì•„í‚¤í…ì²˜ | ì„¤ëª… | ì œì–´ | ìœ ì—°ì„± | ì§€ì—° ì‹œê°„ | ì‚¬ìš© ì‚¬ë¡€ |\n",
        "|---------|------|------|--------|----------|----------|\n",
        "| **2-Step RAG** | ê²€ìƒ‰ í›„ ìƒì„±. ë‹¨ìˆœí•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥ | âœ… ë†’ìŒ | âŒ ë‚®ìŒ | âš¡ ë¹ ë¦„ | FAQ, ë¬¸ì„œ ë´‡ |\n",
        "| **Agentic RAG** | LLM ì—ì´ì „íŠ¸ê°€ ê²€ìƒ‰ ì—¬ë¶€ë¥¼ ê²°ì • | âŒ ë‚®ìŒ | âœ… ë†’ìŒ | â³ ê°€ë³€ | ë‹¤ì¤‘ ë„êµ¬ ì—°êµ¬ ë³´ì¡° |\n",
        "| **Hybrid** | ë‘ ì ‘ê·¼ë²•ì˜ ì¡°í•©, ê²€ì¦ ë‹¨ê³„ í¬í•¨ | âš–ï¸ ì¤‘ê°„ | âš–ï¸ ì¤‘ê°„ | â³ ê°€ë³€ | í’ˆì§ˆ ê²€ì¦ì´ í•„ìš”í•œ Q&A |\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **2-Step RAG**ì™€ **Agentic RAG** ëª¨ë‘ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. ë¬¸ì„œ ë¡œë”© (Document Loading)\n",
        "\n",
        "LangChainì€ ë‹¤ì–‘í•œ ì†ŒìŠ¤(Google Drive, Slack, Notion, PDF ë“±)ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆëŠ” Document Loaderë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” `PyPDFLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•´ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì • (OpenAI RAG ì‹¤ìŠµê³¼ ë™ì¼í•œ ë¬¸ì„œ ì‚¬ìš©)\n",
        "file_path = \"docs/DeepSeek_OCR_paper.pdf\"\n",
        "\n",
        "# PDF ë¡œë” ì´ˆê¸°í™” ë° ë¬¸ì„œ ë¡œë“œ\n",
        "loader = PyPDFLoader(file_path)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"ğŸ“„ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)} í˜ì´ì§€\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì²« ë²ˆì§¸ í˜ì´ì§€ ë‚´ìš© í™•ì¸\n",
        "print(f\"ğŸ“ ì²« ë²ˆì§¸ í˜ì´ì§€ ë‚´ìš© (ì²˜ìŒ 500ì):\\n\")\n",
        "print(docs[0].page_content[:500])\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"\\nğŸ“‹ ë©”íƒ€ë°ì´í„°: {docs[0].metadata}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitting)\n",
        "\n",
        "ë¡œë“œëœ ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì— ë§ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
        "\n",
        "`RecursiveCharacterTextSplitter`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
        "# - chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
        "# - chunk_overlap: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´)\n",
        "# - add_start_index: ì›ë³¸ ë¬¸ì„œì—ì„œì˜ ì‹œì‘ ìœ„ì¹˜ ì¶”ì \n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,      # ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
        "    chunk_overlap=200,    # ì²­í¬ ê°„ ê²¹ì¹¨ (ë¬¸ì ìˆ˜)\n",
        "    add_start_index=True  # ì›ë³¸ ë¬¸ì„œì—ì„œì˜ ì¸ë±ìŠ¤ ì¶”ì \n",
        ")\n",
        "\n",
        "# ë¬¸ì„œ ë¶„í• \n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"âœ‚ï¸ ì›ë³¸ ë¬¸ì„œ {len(docs)}í˜ì´ì§€ê°€ {len(all_splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¶„í• ëœ ì²­í¬ ìƒ˜í”Œ í™•ì¸\n",
        "print(\"ğŸ“¦ ì²« ë²ˆì§¸ ì²­í¬:\")\n",
        "print(f\"ë‚´ìš©: {all_splits[0].page_content[:300]}...\")\n",
        "print(f\"\\në©”íƒ€ë°ì´í„°: {all_splits[0].metadata}\")\n",
        "print(f\"\\nì²­í¬ ê¸¸ì´: {len(all_splits[0].page_content)} ë¬¸ì\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’¡ ì™œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•´ì•¼ í• ê¹Œìš”?\n",
        "\n",
        "1. **ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**: ì‘ì€ ì²­í¬ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ë” ì •í™•í•˜ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "2. **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œ**: LLMì€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ì— ì œí•œì´ ìˆìŠµë‹ˆë‹¤\n",
        "3. **ë¹„ìš© íš¨ìœ¨ì„±**: ì „ì²´ ë¬¸ì„œ ëŒ€ì‹  ê´€ë ¨ ì²­í¬ë§Œ ì „ë‹¬í•˜ì—¬ API ë¹„ìš©ì„ ì ˆì•½í•©ë‹ˆë‹¤\n",
        "\n",
        "`chunk_overlap`ì„ ì„¤ì •í•˜ëŠ” ì´ìœ ëŠ” **ë¬¸ë§¥ì´ ì²­í¬ ê²½ê³„ì—ì„œ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€**í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ\n",
        "\n",
        "ë¶„í• ëœ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë²¡í„° ì €ì¥ì†Œì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ì„ë² ë”©(Embedding)ì´ë€?\n",
        "\n",
        "í…ìŠ¤íŠ¸ë¥¼ **ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜ ë²¡í„°**ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ í…ìŠ¤íŠ¸ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# ì¸ë©”ëª¨ë¦¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ë¬¸ì„œ ì¸ë±ì‹±\n",
        "vector_store = InMemoryVectorStore.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "print(\"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "query = \"DeepSeek-OCR ëª¨ë¸ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "\n",
        "# ìƒìœ„ 3ê°œì˜ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
        "similar_docs = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}\\n\")\n",
        "for i, doc in enumerate(similar_docs, 1):\n",
        "    print(f\"[ê²°ê³¼ {i}]\")\n",
        "    print(f\"ğŸ“„ í˜ì´ì§€: {doc.metadata.get('page', 'N/A')}\")\n",
        "    print(f\"ğŸ“ ë‚´ìš©: {doc.page_content[:200]}...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. 2-Step RAG êµ¬í˜„\n",
        "\n",
        "ê°€ì¥ ê¸°ë³¸ì ì¸ RAG ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. **ê²€ìƒ‰ â†’ ìƒì„±** ë‘ ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "ì‚¬ìš©ì ì§ˆë¬¸ â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± â†’ ì‚¬ìš©ìì—ê²Œ ë°˜í™˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ì±„íŒ… ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Retriever ìƒì„±\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "print(\"âœ… 2-Step RAG êµ¬ì„± ìš”ì†Œ ì¤€ë¹„ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rag_2step(question: str) -> dict:\n",
        "    \"\"\"2-Step RAG êµ¬í˜„: ê²€ìƒ‰ í›„ ìƒì„±\"\"\"\n",
        "    \n",
        "    # Step 1: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "    \n",
        "    # Step 2: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
        "    system_prompt = f\"\"\"You are a helpful assistant who is good at analyzing source information and answering questions.\n",
        "Use the following source documents to answer the user's questions.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Answer in Korean.\n",
        "\n",
        "Documents:\n",
        "{docs_content}\"\"\"\n",
        "    \n",
        "    response = llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ])\n",
        "    \n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer\": response.content,\n",
        "        \"source_documents\": retrieved_docs\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2-Step RAG í…ŒìŠ¤íŠ¸\n",
        "question = \"DeepSeek-OCR ëª¨ë¸ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "result = rag_2step(question)\n",
        "\n",
        "print(f\"â“ ì§ˆë¬¸: {result['question']}\\n\")\n",
        "print(f\"ğŸ’¡ ë‹µë³€: {result['answer']}\\n\")\n",
        "print(f\"ğŸ“š ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(result['source_documents'])}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. RAG Agent êµ¬í˜„\n",
        "\n",
        "ì´ì œ ìµœì‹  LangChain APIì¸ `create_agent`ì™€ `@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ **Agentic RAG**ë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "### Agentic RAGë€?\n",
        "\n",
        "- LLM ì—ì´ì „íŠ¸ê°€ **ê²€ìƒ‰ ì—¬ë¶€ì™€ ë°©ë²•ì„ ìŠ¤ìŠ¤ë¡œ ê²°ì •**í•©ë‹ˆë‹¤\n",
        "- ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ **ì—¬ëŸ¬ ë²ˆì˜ ê²€ìƒ‰**ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- **ë‹¤ì–‘í•œ ë„êµ¬(Tools)**ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "from langsmith import traceable\n",
        "\n",
        "# @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ë„êµ¬ ì •ì˜\n",
        "# response_format=\"content_and_artifact\"ë¡œ ì„¤ì •í•˜ë©´ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ë°˜í™˜ë©ë‹ˆë‹¤\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_context(query: str):\n",
        "    \"\"\"DeepSeek-OCR ë…¼ë¬¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
        "    \n",
        "    Args:\n",
        "        query: ê²€ìƒ‰í•  ë‚´ìš©ì„ ì„¤ëª…í•˜ëŠ” ì¿¼ë¦¬ ë¬¸ìì—´\n",
        "    \n",
        "    Returns:\n",
        "        ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°\n",
        "    \"\"\"\n",
        "    retrieved_docs = retriever.invoke(query)\n",
        "    \n",
        "    # ë¬¸ì„œ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ê²°í•©\n",
        "    content = \"\\n\\n---\\n\\n\".join(\n",
        "        f\"[í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}]\\n{doc.page_content}\" \n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    \n",
        "    # artifactì— ì›ë³¸ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥\n",
        "    artifact = [\n",
        "        {\"page\": doc.metadata.get('page'), \"source\": doc.metadata.get('source')}\n",
        "        for doc in retrieved_docs\n",
        "    ]\n",
        "    \n",
        "    return content, artifact\n",
        "\n",
        "print(\"âœ… ê²€ìƒ‰ ë„êµ¬ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG ì—ì´ì „íŠ¸ ìƒì„±\n",
        "tools = [retrieve_context]\n",
        "\n",
        "system_prompt = \"\"\"You are a helpful assistant specialized in analyzing academic papers.\n",
        "You have access to a tool that retrieves context from the DeepSeek-OCR paper.\n",
        "Use the tool whenever you need specific information from the paper.\n",
        "\n",
        "Guidelines:\n",
        "- Always use the retrieve_context tool to find relevant information before answering\n",
        "- If the first search doesn't provide enough information, try different search queries\n",
        "- Answer in Korean\n",
        "\"\"\"\n",
        "\n",
        "rag_agent = create_agent(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    tools=tools,\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ - ë‹¨ì¼ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
        "question = \"DeepSeek-OCRì˜ ì••ì¶•ë¥ (compression ratio)ì€ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
        "\n",
        "print(f\"â“ ì§ˆë¬¸: {question}\\n\")\n",
        "print(\"ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ ê³¼ì •:\\n\")\n",
        "\n",
        "for event in rag_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ - ë³µí•© ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
        "complex_question = \"\"\"DeepSeek-OCRì˜ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "ê·¸ë¦¬ê³  OmniDocBenchì—ì„œì˜ ì„±ëŠ¥ì€ ì–´ë–¤ê°€ìš”?\"\"\"\n",
        "\n",
        "print(f\"â“ ë³µí•© ì§ˆë¬¸: {complex_question}\\n\")\n",
        "print(\"ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ ê³¼ì •:\\n\")\n",
        "\n",
        "for event in rag_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": complex_question}]},\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’¡ Agentic RAGì˜ ì¥ì \n",
        "\n",
        "1. **ë™ì  ê²€ìƒ‰**: ì§ˆë¬¸ì˜ ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ íšŸìˆ˜ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤\n",
        "2. **ë‹¤ì¤‘ ì¿¼ë¦¬**: í•˜ë‚˜ì˜ ì§ˆë¬¸ì—ì„œ ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "3. **ë„êµ¬ í™•ì¥**: ì›¹ ê²€ìƒ‰, ê³„ì‚°ê¸° ë“± ë‹¤ë¥¸ ë„êµ¬ì™€ ê²°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### ğŸ“š ì°¸ê³  ìë£Œ\n",
        "\n",
        "- [LangChain Retrieval Documentation](https://docs.langchain.com/oss/python/langchain/retrieval)\n",
        "- [LangChain RAG Tutorial](https://docs.langchain.com/oss/python/langchain/rag)\n",
        "- [LangGraph Agentic RAG](https://docs.langchain.com/oss/python/langgraph/agentic-rag)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
