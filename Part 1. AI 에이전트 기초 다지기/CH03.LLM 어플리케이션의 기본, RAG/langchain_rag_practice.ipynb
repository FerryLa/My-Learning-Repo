{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f349b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install -qU langchain langchain-openai langchain-community langchain-text-splitters pypdf python-dotenv langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26881100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì • (OpenAI RAG ì‹¤ìŠµê³¼ ë™ì¼í•œ ë¬¸ì„œ ì‚¬ìš©)\n",
    "file_path = \"docs/DeepSeek_OCR_paper.pdf\"\n",
    "\n",
    "# PDF ë¡œë” ì´ˆê¸°í™” ë° ë¬¸ì„œ ë¡œë“œ\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"ğŸ“„ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)} í˜ì´ì§€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ í˜ì´ì§€ ë‚´ìš© í™•ì¸\n",
    "print(f\"ğŸ“ ì²« ë²ˆì§¸ í˜ì´ì§€ ë‚´ìš© (ì²˜ìŒ 500ì):\\n\")\n",
    "print(docs[0].page_content[:500])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nğŸ“‹ ë©”íƒ€ë°ì´í„°: {docs[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ca1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "# - chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "# - chunk_overlap: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´)\n",
    "# - add_start_index: ì›ë³¸ ë¬¸ì„œì—ì„œì˜ ì‹œì‘ ìœ„ì¹˜ ì¶”ì \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
    "    chunk_overlap=200,    # ì²­í¬ ê°„ ê²¹ì¹¨ (ë¬¸ì ìˆ˜)\n",
    "    add_start_index=True  # ì›ë³¸ ë¬¸ì„œì—ì„œì˜ ì¸ë±ìŠ¤ ì¶”ì \n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"âœ‚ï¸ ì›ë³¸ ë¬¸ì„œ {len(docs)}í˜ì´ì§€ê°€ {len(all_splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf24ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„í• ëœ ì²­í¬ ìƒ˜í”Œ í™•ì¸\n",
    "print(\"ğŸ“¦ ì²« ë²ˆì§¸ ì²­í¬:\")\n",
    "print(f\"ë‚´ìš©: {all_splits[0].page_content[:300]}...\")\n",
    "print(f\"\\në©”íƒ€ë°ì´í„°: {all_splits[0].metadata}\")\n",
    "print(f\"\\nì²­í¬ ê¸¸ì´: {len(all_splits[0].page_content)} ë¬¸ì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ì¸ë©”ëª¨ë¦¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ë¬¸ì„œ ì¸ë±ì‹±\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cdef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "query = \"DeepSeek-OCR ëª¨ë¸ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# ìƒìœ„ 3ê°œì˜ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "similar_docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}\\n\")\n",
    "for i, doc in enumerate(similar_docs, 1):\n",
    "    print(f\"[ê²°ê³¼ {i}]\")\n",
    "    print(f\"ğŸ“„ í˜ì´ì§€: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(f\"ğŸ“ ë‚´ìš©: {doc.page_content[:200]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì±„íŒ… ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Retriever ìƒì„±\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "print(\"âœ… 2-Step RAG êµ¬ì„± ìš”ì†Œ ì¤€ë¹„ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_2step(question: str) -> dict:\n",
    "    \"\"\"2-Step RAG êµ¬í˜„: ê²€ìƒ‰ í›„ ìƒì„±\"\"\"\n",
    "    \n",
    "    # Step 1: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    \n",
    "    # Step 2: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    system_prompt = f\"\"\"You are a helpful assistant who is good at analyzing source information and answering questions.\n",
    "Use the following source documents to answer the user's questions.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Answer in Korean.\n",
    "\n",
    "Documents:\n",
    "{docs_content}\"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": response.content,\n",
    "        \"source_documents\": retrieved_docs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Step RAG í…ŒìŠ¤íŠ¸\n",
    "question = \"DeepSeek-OCR ëª¨ë¸ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "result = rag_2step(question)\n",
    "\n",
    "print(f\"â“ ì§ˆë¬¸: {result['question']}\\n\")\n",
    "print(f\"ğŸ’¡ ë‹µë³€: {result['answer']}\\n\")\n",
    "print(f\"ğŸ“š ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(result['source_documents'])}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c633890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langsmith import traceable\n",
    "\n",
    "# @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ë„êµ¬ ì •ì˜\n",
    "# response_format=\"content_and_artifact\"ë¡œ ì„¤ì •í•˜ë©´ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ë°˜í™˜ë©ë‹ˆë‹¤\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"DeepSeek-OCR ë…¼ë¬¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰í•  ë‚´ìš©ì„ ì„¤ëª…í•˜ëŠ” ì¿¼ë¦¬ ë¬¸ìì—´\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°\n",
    "    \"\"\"\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    # ë¬¸ì„œ ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    content = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"[í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}]\\n{doc.page_content}\" \n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    \n",
    "    # artifactì— ì›ë³¸ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "    artifact = [\n",
    "        {\"page\": doc.metadata.get('page'), \"source\": doc.metadata.get('source')}\n",
    "        for doc in retrieved_docs\n",
    "    ]\n",
    "    \n",
    "    return content, artifact\n",
    "\n",
    "print(\"âœ… ê²€ìƒ‰ ë„êµ¬ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì—ì´ì „íŠ¸ ìƒì„±\n",
    "tools = [retrieve_context]\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant specialized in analyzing academic papers.\n",
    "You have access to a tool that retrieves context from the DeepSeek-OCR paper.\n",
    "Use the tool whenever you need specific information from the paper.\n",
    "\n",
    "Guidelines:\n",
    "- Always use the retrieve_context tool to find relevant information before answering\n",
    "- If the first search doesn't provide enough information, try different search queries\n",
    "- Answer in Korean\n",
    "\"\"\"\n",
    "\n",
    "rag_agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ - ë‹¨ì¼ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "question = \"DeepSeek-OCRì˜ ì••ì¶•ë¥ (compression ratio)ì€ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
    "\n",
    "print(f\"â“ ì§ˆë¬¸: {question}\\n\")\n",
    "print(\"ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ ê³¼ì •:\\n\")\n",
    "\n",
    "for event in rag_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ - ë³µí•© ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "complex_question = \"\"\"DeepSeek-OCRì˜ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "ê·¸ë¦¬ê³  OmniDocBenchì—ì„œì˜ ì„±ëŠ¥ì€ ì–´ë–¤ê°€ìš”?\"\"\"\n",
    "\n",
    "print(f\"â“ ë³µí•© ì§ˆë¬¸: {complex_question}\\n\")\n",
    "print(\"ğŸ¤– ì—ì´ì „íŠ¸ ì‘ë‹µ ê³¼ì •:\\n\")\n",
    "\n",
    "for event in rag_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": complex_question}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b9baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
