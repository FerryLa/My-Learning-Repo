{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MCP Servers with Strands Agents\n",
    "\n",
    "This notebook demonstrates how to integrate Model Context Protocol (MCP) servers as tools for Strands Agents. MCP provides a standardized way to extend AI agents with external tools and data sources, enabling more powerful and specialized capabilities beyond basic language model interactions. By connecting MCP servers to your agents, you can access file systems, databases, APIs, and custom business logic seamlessly.\n",
    "\n",
    "**Why use MCP servers?** They eliminate the need to rebuild common functionality, provide secure sandboxed tool execution, and enable modular agent architectures that can be easily extended and maintained.\n",
    "\n",
    "**Key takeaways:** You'll learn to configure existing MCP servers for immediate productivity gains, build custom servers tailored to your specific use cases, and understand best practices for local development and deployment of MCP-enabled agent systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequsites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T02:39:12.826427Z",
     "iopub.status.busy": "2025-09-12T02:39:12.826151Z",
     "iopub.status.idle": "2025-09-12T02:39:23.077622Z",
     "shell.execute_reply": "2025-09-12T02:39:23.076909Z",
     "shell.execute_reply.started": "2025-09-12T02:39:12.826401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install all required packages from requirements.txt\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:47:58.713908Z",
     "iopub.status.busy": "2025-09-12T22:47:58.713502Z",
     "iopub.status.idle": "2025-09-12T22:47:58.717646Z",
     "shell.execute_reply": "2025-09-12T22:47:58.717064Z",
     "shell.execute_reply.started": "2025-09-12T22:47:58.713885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os, time, boto3, json\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import use_aws, file_write, journal, file_read, file_write, sleep, python_repl, retrieve, current_time\n",
    "from strands.telemetry import StrandsTelemetry\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "# Bypass tool consent for automated execution\n",
    "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"\n",
    "os.environ[\"PYTHON_REPL_INTERACTIVE\"] = \"False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:48:00.684135Z",
     "iopub.status.busy": "2025-09-12T22:48:00.683867Z",
     "iopub.status.idle": "2025-09-12T22:48:00.687333Z",
     "shell.execute_reply": "2025-09-12T22:48:00.686820Z",
     "shell.execute_reply.started": "2025-09-12T22:48:00.684113Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d %H:%M:%S',\n",
    "    filename='strands_debug.log'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A simple agent without any tool\n",
    "##### Let's see how a simple Strands Agent works\n",
    "![Write code](just_the_ai_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:48:02.327592Z",
     "iopub.status.busy": "2025-09-12T22:48:02.327331Z",
     "iopub.status.idle": "2025-09-12T22:48:15.759297Z",
     "shell.execute_reply": "2025-09-12T22:48:15.758790Z",
     "shell.execute_reply.started": "2025-09-12T22:48:02.327572Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Give a task to the agent\n",
    "task = f\"\"\"\n",
    "Write Python code to find differentiation of a quadratic equation.\n",
    "\"\"\"\n",
    "\n",
    "# Defne a model. Initialize Claude 3.7 Sonnet model via Bedrock\n",
    "model = BedrockModel(model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\", temperature=0.1)\n",
    "\n",
    "# Define an agent. Initialize a Strands Agent with the model\n",
    "agent = Agent(model=model)\n",
    "\n",
    "# Give the task to the agent\n",
    "response = agent(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Let's add built-in Strands Agent tool\n",
    "*Let's execute the python code using a built-in tool*\n",
    "\n",
    "Now, we will give *tools* to the agent. Tools can be provided as Python libraries. Strands Agents provides built-in tools as a part of the open-source project.\n",
    "Remember, these tools are functions running inside the same compute engine as the agent itself.\n",
    "\n",
    "![Execute code](ai_agent_tool.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:49:26.332550Z",
     "iopub.status.busy": "2025-09-12T22:49:26.332292Z",
     "iopub.status.idle": "2025-09-12T22:49:57.186347Z",
     "shell.execute_reply": "2025-09-12T22:49:57.185824Z",
     "shell.execute_reply.started": "2025-09-12T22:49:26.332530Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Give a task to the agent\n",
    "task = f\"\"\"\n",
    "Write Python code to find differentiation of a qudratic equation using Numpy.\n",
    "Print the results for this equation y = 20*(x**3) + 30*(x**2) - 7.\n",
    "\"\"\"\n",
    "\n",
    "# Defne a model. Initialize Claude 3.7 Sonnet model via Bedrock\n",
    "model = BedrockModel(model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\", temperature=0.1)\n",
    "\n",
    "# Define an agent. Initialize a Strands Agent with the model,\n",
    "# python_repl tool helps execute the python code\n",
    "# file_write tool helps save the code to a python file\n",
    "agent = Agent(model=model, tools=[python_repl, file_write])\n",
    "\n",
    "# Give the task to the agent\n",
    "response = agent(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Adding an MCP client as a tool for a remote server\n",
    "\n",
    "Now, we will extend the scope of tools to remote services.\n",
    "<br/>\n",
    "Following cell shows an example that requires access to AWS documents. AWS Lab provides an MCP server which provides a knowledge base for AWS documentations. <br/>\n",
    "By using this, Stands Agents can retrieve documents without implementing its own knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:02:16.050631Z",
     "iopub.status.busy": "2025-09-12T23:02:16.050372Z",
     "iopub.status.idle": "2025-09-12T23:02:20.431778Z",
     "shell.execute_reply": "2025-09-12T23:02:20.431320Z",
     "shell.execute_reply.started": "2025-09-12T23:02:16.050611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ask a question that is very specific to your corporate product or process.\n",
    "# The agent will not be able to answer the question, assuming it has never seen that data when it was trained.\n",
    "from IPython.display import display, Markdown\n",
    "answer = agent(\"I want to learn about Amazon Bedrock AgentCore which was announced in July 2025.\"\n",
    "      \"Explain the difference between Bedrock AgentCore short-term memory and long-term memory\").message[\"content\"][0][\"text\"]\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create an MCP Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:56:50.033918Z",
     "iopub.status.busy": "2025-09-12T22:56:50.033649Z",
     "iopub.status.idle": "2025-09-12T22:56:50.339872Z",
     "shell.execute_reply": "2025-09-12T22:56:50.339349Z",
     "shell.execute_reply.started": "2025-09-12T22:56:50.033897Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's create a reusable function to create an MCPP Client\n",
    "\n",
    "# Import MCP client libraries\n",
    "from mcp import stdio_client, StdioServerParameters # Core MCP protocol components\n",
    "from strands.tools.mcp import MCPClient # Strands wrapper for MCP functionality\n",
    "\n",
    "# Typical usage of the following function is:\n",
    "# aws_doc_client = create_mcp_client(\"uvx\", [\"awslabs.aws-documentation-mcp-server@latest\"])\n",
    "# uvx is a python package runner. \n",
    "# awslabs.aws-documentation-mcp-server@latest is an MCP server\n",
    "\n",
    "def create_mcp_client(command, args, env={\"AWS_REGION\": \"us-west-2\",\"FASTMCP_LOG_LEVEL\": \"ERROR\"}):\n",
    "    return MCPClient(lambda: stdio_client( # The MCP client created connects to the MSCP server via stdin/stdout\n",
    "        StdioServerParameters(  # Configures how to launch the MCP server process\n",
    "            command= command, # The executable to run such as uvx, which is a python package runner\n",
    "            args= args, # One of the argument can be the package name of MCP server that needs to be downloaded and run as a sub process\n",
    "            env= env\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's use an MCP Server awslabs.aws-documentation-mcp-server@latest\n",
    "It's a documentation mcp server that will search and answer AWS documentation related questions\n",
    "![Tools from Documentation MCP Server](tools_from_doc_MCP_server2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:57:33.877965Z",
     "iopub.status.busy": "2025-09-12T22:57:33.877699Z",
     "iopub.status.idle": "2025-09-12T22:57:36.035093Z",
     "shell.execute_reply": "2025-09-12T22:57:36.034569Z",
     "shell.execute_reply.started": "2025-09-12T22:57:33.877944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's first print the tools that the MCP server offers and its description\n",
    "# Keep in mind that the LLM uses the tool description to determine if it's the right tool for a task.\n",
    "\n",
    "#create the client\n",
    "aws_doc_client = create_mcp_client(\"uvx\", [\"awslabs.aws-documentation-mcp-server@latest\"])\n",
    "\n",
    "with aws_doc_client:\n",
    "    # Get the tools that the mcp client has to offer\n",
    "    doc_tools = aws_doc_client.list_tools_sync()\n",
    "\n",
    "    for tool in doc_tools:\n",
    "        print(f\"Tool: {tool.tool_name}\")\n",
    "        if hasattr(tool, 'tool_spec'):            \n",
    "            print(f\"Tool: {tool.tool_spec['description']}\")\n",
    "            print(json.dumps(tool.tool_spec, indent=2)) # uncomment this to see function parameters and what they mean               \n",
    "#       print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:06:53.396836Z",
     "iopub.status.busy": "2025-09-12T23:06:53.396572Z",
     "iopub.status.idle": "2025-09-12T23:06:53.399610Z",
     "shell.execute_reply": "2025-09-12T23:06:53.399006Z",
     "shell.execute_reply.started": "2025-09-12T23:06:53.396815Z"
    }
   },
   "source": [
    "#### Step 2: Let the agent to use the MCP client as a tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:04:18.671100Z",
     "iopub.status.busy": "2025-09-12T23:04:18.670845Z",
     "iopub.status.idle": "2025-09-12T23:04:58.151900Z",
     "shell.execute_reply": "2025-09-12T23:04:58.151400Z",
     "shell.execute_reply.started": "2025-09-12T23:04:18.671080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let us ask the same question to an agent using MCP as a tool\n",
    "task = \"\"\"I want to learn about Amazon Bedrock AgentCore which was announced in July 2025.\n",
    "       Explain the difference between Bedrock AgentCore short-term memory and long-term memory\"\"\"\n",
    "\n",
    "#create the client\n",
    "aws_doc_client = create_mcp_client(\"uvx\", [\"awslabs.aws-documentation-mcp-server@latest\"])\n",
    "\n",
    "#create the model\n",
    "model = BedrockModel(model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\", temperature=0.1)\n",
    "# model = BedrockModel(model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\", temperature=0.1)\n",
    "# model = BedrockModel(model_id=\"us.deepseek.r1-v1:0\", temperature=0.1)\n",
    "# model = BedrockModel(model_id=\"openai.gpt-oss-120b-1:0\", temperature=0.1)\n",
    "\n",
    "with aws_doc_client:\n",
    "    # Get the tools that the mcp client has to offer\n",
    "    doc_tools = aws_doc_client.list_tools_sync()\n",
    "\n",
    "    #create the agent and pass the tools recieved from the MCP client\n",
    "    aws_doc_agent = Agent(model=model, tools=[doc_tools])\n",
    "    answer = aws_doc_agent(task).message[\"content\"][0][\"text\"]\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let's use multiple MCP Servers and a tool in the same Agent\n",
    "![Multiple MCP Servers](multiple_mcp_servers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:09:38.702460Z",
     "iopub.status.busy": "2025-09-12T23:09:38.702194Z",
     "iopub.status.idle": "2025-09-12T23:12:13.606330Z",
     "shell.execute_reply": "2025-09-12T23:12:13.605826Z",
     "shell.execute_reply.started": "2025-09-12T23:09:38.702440Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use multiple MCP servers and a tool to research Amazon SgaeMaker.\n",
    "# Store the research in a file and pricing info in a dynamo db table.\n",
    "task = \"\"\"\n",
    "- What are the features and benefits of Amazon Sagemaker's fine tuning ability of large language models. Store the various features and benefits in dictionary format in a Dynamo DB table named my_ddb_for_sagemaker\n",
    "- How can I fine tune LLama 8B model using SageMaker?\n",
    "- What type of SageMaker instances would I need to fine tune Llama 8B model?\n",
    "- How much do they cost?\n",
    "- Store the instance - cost info in the same Dynamo DB table.\n",
    "- Use aws region us-west-2 for all these tasks.\n",
    "- Write all the above research on SageMaker to a file named sagemaker_research.md in markdown format.\n",
    "\"\"\"\n",
    "\n",
    "#create the client for pricing MCP server\n",
    "aws_price_client = create_mcp_client(\"uvx\", [\"awslabs.aws-pricing-mcp-server@latest\"])\n",
    "\n",
    "#create the client for Dynamo DB MCP server\n",
    "ddb_client = create_mcp_client(\"uvx\", [\"awslabs.dynamodb-mcp-server@latest\"])\n",
    "\n",
    "model = BedrockModel(model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\", temperature=0.1)\n",
    "\n",
    "aws_price_agent = None\n",
    "response = \"\"\n",
    "with aws_price_client, aws_doc_client, ddb_client: # Specify multiple MCP clients\n",
    "    # Get the tools from the MCP servers and concat them\n",
    "    price_tools = aws_price_client.list_tools_sync()\n",
    "    doc_tools = aws_doc_client.list_tools_sync()\n",
    "    ddb_tools = ddb_client.list_tools_sync()\n",
    "    all_tools = price_tools + doc_tools + ddb_tools + [file_write]\n",
    "\n",
    "    #create the agent and pass the tools recieved from the MCP servers\n",
    "    sagemaker_research_agent = Agent(model=model, tools=[all_tools])\n",
    "\n",
    "    response = sagemaker_research_agent(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4>Learn about all the MCP Servers from <a href=\"https://awslabs.github.io/mcp/\">AWS Labs here.</a> </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Let's Create a Basic MCP Server\n",
    "##### Step1. Create a Python script with functions, using FastMCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:15:12.326767Z",
     "iopub.status.busy": "2025-09-12T23:15:12.326491Z",
     "iopub.status.idle": "2025-09-12T23:15:12.330887Z",
     "shell.execute_reply": "2025-09-12T23:15:12.330377Z",
     "shell.execute_reply.started": "2025-09-12T23:15:12.326745Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile my_mcp_server.py \n",
    "\n",
    "from fastmcp import FastMCP\n",
    "import asyncio\n",
    "\n",
    "#create MCP server\n",
    "mcp = FastMCP(\"My First MCP Server\") # Creates an MCP server that can host your tools\n",
    "\n",
    "@mcp.tool() #  Decorator that turns your Python functions into MCP tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@mcp.tool()\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step2. Create an agent that uses the above MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:16:17.228964Z",
     "iopub.status.busy": "2025-09-12T23:16:17.228701Z",
     "iopub.status.idle": "2025-09-12T23:16:26.896526Z",
     "shell.execute_reply": "2025-09-12T23:16:26.895965Z",
     "shell.execute_reply.started": "2025-09-12T23:16:17.228943Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_mcp_client = create_mcp_client(\"python3\", [\"my_mcp_server.py\"]) #Create an MCP client that connects to the MCP server\n",
    "\n",
    "# specify the model\n",
    "# model = BedrockModel(model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\", temperature=0.1)\n",
    "model = BedrockModel(model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\", temperature=0.1)\n",
    "\n",
    "custom_mcp_agent = None\n",
    "with custom_mcp_client:\n",
    "    # Get the tools that the mcp client has to offer\n",
    "    custom_mcp_tools = custom_mcp_client.list_tools_sync()\n",
    "\n",
    "    #create the agent and pass the tools recieved from the MCP client\n",
    "    custom_mcp_agent = Agent(model=model, tools=[custom_mcp_tools])\n",
    "\n",
    "    response = custom_mcp_agent(f\"What is (10*5-7+20)/9?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Let's Build an MCP server with more meaningful functions\n",
    "*Our MCP server will help 1/ query a Bedrock Knowledge Base, 2/ Rerank the query results from Knowledge Base.*<br>\n",
    "*Amazon Bedrock Knowledge Base is a fully managed service that is useful in retrieval augmented generation (RAG) applications.*<br>\n",
    "*It automatically handles data ingestion, chunking, embedding generation, and vector storage, enabling AI applications to provide accurate responses grounded in your organization's specific information.*<br>\n",
    "*Once the chunks of data are retrueved from Bedrock Knowledge Base, you can further improve accuracy by re-ranking those chunks and pick the top ranked chunks to be sent to an LLM.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption: Bedrock Knowledge Base has already been Created.\n",
    "Please store your Knowledge Base ID and the AWS region in kb.txt file.\n",
    "![Document Igestion](doc_ingestion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MCP Server to retrieve and re-rank content from Bedrock Knowledge Base\n",
    "![Document Retrieval Reranking](retrieve_re-rank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Python script with FastMCP decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:33:53.957182Z",
     "iopub.status.busy": "2025-09-12T23:33:53.956914Z",
     "iopub.status.idle": "2025-09-12T23:33:53.962262Z",
     "shell.execute_reply": "2025-09-12T23:33:53.961774Z",
     "shell.execute_reply.started": "2025-09-12T23:33:53.957162Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile kb_mcp_server.py\n",
    "from fastmcp import FastMCP\n",
    "import asyncio\n",
    "\n",
    "from typing import Dict, List, Any, Optional, Union, Tuple\n",
    "import boto3, json\n",
    "\n",
    "# create MCP server\n",
    "kb_mcp = FastMCP(\"My KB MCP Server\") # Creates an MCP server that can host your tools\n",
    "\n",
    "@kb_mcp.tool\n",
    "def retrieve_from_kb(query: str, knowledge_base_id: str, max_results: int = 10, region_name = \"us-west-2\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieves query search results from Bedrock Knowledge Base\n",
    "\n",
    "    Args:\n",
    "        query (str): The input query\n",
    "        knowledge_base_id (str): The ID of the knowledge base\n",
    "        num_results (int): Number of results to retrieve, defaults to 10\n",
    "        region_name (str): AWS region, defaults to us-west-2\n",
    "        \n",
    "    Returns:\n",
    "        List: Returns List of str\n",
    "    \"\"\"\n",
    "    \n",
    "    client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "    \n",
    "    kb_response = client.retrieve(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        retrievalQuery={\n",
    "            \"text\": query\n",
    "        },\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": max_results,\n",
    "                \"overrideSearchType\": \"HYBRID\"  # SEMANTIC, HYBRID\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    # Extract documents and metadata\n",
    "    documents = []\n",
    "    original_results = []\n",
    "    \n",
    "    for i, result in enumerate(kb_response.get(\"retrievalResults\", [])):\n",
    "        # Extract text from result\n",
    "        text = \"\"\n",
    "        if \"content\" in result and \"text\" in result[\"content\"]:\n",
    "            content_text = result[\"content\"][\"text\"]\n",
    "            if isinstance(content_text, list):\n",
    "                text = \" \".join([item.get(\"span\", \"\") if isinstance(item, dict) else str(item) \n",
    "                                for item in content_text])\n",
    "            else:\n",
    "                text = str(content_text)\n",
    "            \n",
    "        # Store original result with metadata\n",
    "        original_results.append({\n",
    "            \"position\": i + 1,\n",
    "            \"score\": result.get(\"scoreValue\", 0),\n",
    "            \"text\": text\n",
    "        })\n",
    "        documents.append(text)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "@kb_mcp.tool\n",
    "def rerank_results(\n",
    "    query,\n",
    "    documents,\n",
    "    rerank_model_arn = \"arn:aws:bedrock:us-west-2::foundation-model/amazon.rerank-v1:0\",\n",
    "    reranked_result_count=5,\n",
    "    region_name=\"us-west-2\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Rerank search results using a Bedrock reranking model.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query\n",
    "        documents (list): List of document texts to rerank\n",
    "        rerank_model_arn (str): ARN of the reranking model\n",
    "        reranked_result_count (int): Number of reranked results to return, defaults to 5\n",
    "        region_name (str): AWS region name, defaults to us-west-2\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing original and reranked results\n",
    "    \"\"\"\n",
    "    import boto3\n",
    "    \n",
    "    bedrock_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "    \n",
    "    try:\n",
    "        # Invoke the rerank API\n",
    "        reranked = bedrock_client.rerank(\n",
    "            queries=[{\"textQuery\": {\"text\": query}, \"type\": \"TEXT\"}],\n",
    "            rerankingConfiguration={\n",
    "                \"bedrockRerankingConfiguration\": {\n",
    "                    \"modelConfiguration\": {\"modelArn\": rerank_model_arn},\n",
    "                    \"numberOfResults\": reranked_result_count\n",
    "                },\n",
    "                \"type\": \"BEDROCK_RERANKING_MODEL\"\n",
    "            },\n",
    "            sources=[{\n",
    "                \"inlineDocumentSource\": {\"textDocument\": {\"text\": doc}, \"type\": \"TEXT\"},\n",
    "                \"type\": \"INLINE\"\n",
    "            } for doc in documents]\n",
    "        )\n",
    "        \n",
    "        # Process reranked results\n",
    "        reranked_results = []\n",
    "        for result in reranked.get(\"results\", []):\n",
    "            idx = result.get(\"index\", 0)\n",
    "            if 0 <= idx < len(documents):\n",
    "                reranked_results.append({\n",
    "                    \"original_position\": idx + 1,\n",
    "                    \"new_position\": len(reranked_results) + 1,\n",
    "                    \"relevance_score\": result.get(\"relevanceScore\", 0),  # Full precision score\n",
    "                    \"text\": documents[idx]\n",
    "                })\n",
    "        \n",
    "        return {\"original_results\": documents, \"reranked_results\": reranked_results}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Reranking failed: {str(e)}\")\n",
    "        return {\"original_results\": documents, \"reranked_results\": []}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # mcp.run(transport=\"streamable-http\")\n",
    "    kb_mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use the above MCP Server we created\n",
    "We stored the Bedrock Knowledge Base ID and th AWS region in a file named kb.txt, which the Agent wille xtract and use.<br>\n",
    "The Agent will use the MCP server to get the retirve and re-rank tools and pass them to the Agent.<br> \n",
    "For the input query, the Agent will query Bedrock Knowledge Base for relevant chunks, re-rank and send the chunks to the Agent.<br>\n",
    "This approach of retrieve and rerank using embeddings stored in Bedrock Knwoledge Base is a much better approach than the one we used before to search AWS Documentation because that MCP server does not use vector embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:34:02.371777Z",
     "iopub.status.busy": "2025-09-12T23:34:02.371521Z",
     "iopub.status.idle": "2025-09-12T23:34:26.382958Z",
     "shell.execute_reply": "2025-09-12T23:34:26.382448Z",
     "shell.execute_reply.started": "2025-09-12T23:34:02.371757Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Extract Bedrock Knowledge base ID and AWS region from kb.txt file for querying Bedrock Knowledge Base.\n",
    "Use the information to query Bedrock Knwoeldgebase and rerank.\n",
    "\"\"\"\n",
    "\n",
    "task = f\"\"\"\n",
    "- What is Bedrock AgentCore Memory, Runtime, and Gateway? \n",
    "- How are they relevant to a healthcare customer?\n",
    "- Now explain to me as if I am a 15-year old.\n",
    "\"\"\"\n",
    "\n",
    "# Create the MCP client\n",
    "kb_custom_mcp_client = create_mcp_client(\"python3\", [\"kb_mcp_server.py\"])\n",
    "\n",
    "kb_custom_mcp_agent = None\n",
    "response = \"\"\n",
    "with kb_custom_mcp_client:\n",
    "    # Get the tools that the mcp client has to offer\n",
    "    kb_custom_mcp_tools = kb_custom_mcp_client.list_tools_sync()\n",
    "    all_tools = kb_custom_mcp_tools + [file_read]\n",
    "\n",
    "    #create the agent and pass the tools recieved from the MCP client\n",
    "    custom_mcp_agent = Agent(model=model, tools=all_tools, system_prompt=system_prompt)\n",
    "\n",
    "    response = custom_mcp_agent(task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
