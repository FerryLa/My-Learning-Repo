{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸŒ LangGraph ê¸°ë°˜ EXA ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì‹¤ìŠµ\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **EXA Search API**ë¥¼ í™œìš©í•œ ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ **3ê°€ì§€ ë°©ì‹**ìœ¼ë¡œ êµ¬í˜„í•´ë³´ë©°, ê° ë°©ì‹ì˜ íŠ¹ì§•ê³¼ ì¥ë‹¨ì ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
        "\n",
        "> ğŸ“¢ **EXA Searchë€?**\n",
        "> \n",
        "> EXAëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ì„¤ê³„ëœ **ì°¨ì„¸ëŒ€ ì›¹ ê²€ìƒ‰ API**ì…ë‹ˆë‹¤.\n",
        "> - **ì‹ ê²½ë§ ê¸°ë°˜ ê²€ìƒ‰**: í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰\n",
        "> - **ì‹¤ì‹œê°„ ì›¹ ë°ì´í„°**: ìµœì‹  ì •ë³´ ê²€ìƒ‰ ê°€ëŠ¥\n",
        "> - **ê³ í’ˆì§ˆ ê²°ê³¼**: SEO ìŠ¤íŒ¸ì„ í•„í„°ë§í•œ ê¹¨ë—í•œ ê²°ê³¼\n",
        "\n",
        "### ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
        "1. LangChainì˜ `create_agent`ë¡œ ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ êµ¬í˜„\n",
        "2. LangGraphì˜ StateGraphë¡œ ì„¸ë°€í•œ Tool Call Routing êµ¬í˜„\n",
        "4. ê° ë°©ì‹ì˜ ì¥ë‹¨ì  ë¹„êµ ë° ì„ íƒ ê¸°ì¤€ ì´í•´\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ ëª©ì°¨\n",
        "\n",
        "### Part A: LangChain create_agent (ê¸°ë³¸)\n",
        "1. [í™˜ê²½ ì„¤ì •](#1-í™˜ê²½-ì„¤ì •)\n",
        "2. [EXA Search Tool ìƒì„±](#2-exa-search-tool-ìƒì„±)\n",
        "3. [LangChain create_agent](#3-langchain-create_agent)\n",
        "\n",
        "### Part B: LangGraph Tool Call Routing (ì‹¬í™”)\n",
        "4. [LangGraph ìƒíƒœ ì •ì˜](#4-langgraph-ìƒíƒœ-ì •ì˜)\n",
        "5. [ê·¸ë˜í”„ ë…¸ë“œ ë° ì—£ì§€ êµ¬í˜„](#5-ê·¸ë˜í”„-ë…¸ë“œ-ë°-ì—£ì§€-êµ¬í˜„)\n",
        "6. [Tool Call Routing ì—ì´ì „íŠ¸ ì‹¤í–‰](#6-tool-call-routing-ì—ì´ì „íŠ¸-ì‹¤í–‰)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ğŸ”§ Part A: LangChain create_agent (ê¸°ë³¸)\n",
        "\n",
        "## 1. í™˜ê²½ ì„¤ì •\n",
        "\n",
        "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•˜ê³  í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "# %pip install -qU langchain langchain-openai langgraph langchain-exa exa-py python-dotenv\n",
        "%pip install -qU langchain-exa exa-py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# API í‚¤ ì„¤ì •\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
        "\n",
        "# EXA API í‚¤ (https://exa.ai ì—ì„œ ë°œê¸‰)\n",
        "if not os.getenv(\"EXA_API_KEY\"):\n",
        "    os.environ[\"EXA_API_KEY\"] = \"your-exa-api-key\"\n",
        "\n",
        "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. EXA Search Tool ìƒì„±\n",
        "\n",
        "EXAì˜ ê²€ìƒ‰ ê¸°ëŠ¥ì„ LangChain Toolë¡œ ë˜í•‘í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from exa_py import Exa\n",
        "\n",
        "# EXA í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "exa_client = Exa(api_key=os.environ[\"EXA_API_KEY\"])\n",
        "\n",
        "@tool\n",
        "def exa_web_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    EXAë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
        "    ìµœì‹  ë‰´ìŠ¤, ê¸°ìˆ  íŠ¸ë Œë“œ, ì—°êµ¬ ë…¼ë¬¸ ë“±ì„ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "    \n",
        "    Args:\n",
        "        query: ê²€ìƒ‰í•  ì§ˆë¬¸ì´ë‚˜ í‚¤ì›Œë“œ\n",
        "    \"\"\" \n",
        "    results = exa_client.search_and_contents(\n",
        "        query=query,\n",
        "        num_results=5,\n",
        "        text={\"max_characters\": 1000},\n",
        "        highlights={\"num_sentences\": 3}\n",
        "    )\n",
        "    \n",
        "    output = []\n",
        "    for result in results.results:\n",
        "        output.append(f\"**Title**: {result.title}\")\n",
        "        output.append(f\"**URL**: {result.url}\")\n",
        "        if result.highlights:\n",
        "            output.append(f\"**Highlights**: {' '.join(result.highlights)}\")\n",
        "        output.append(\"---\")\n",
        "    \n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "print(\"âœ… EXA Search Tool ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXA ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "test_result = exa_web_search.invoke({\"query\": \"LangGraph agent framework\"})\n",
        "print(\"ğŸ” EXA ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:\\n\")\n",
        "print(test_result[:1000] + \"...\" if len(test_result) > 1000 else test_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. LangChain create_agent\n",
        "\n",
        "LangChainì˜ **`create_agent`**ëŠ” ReAct(Reasoning + Acting) íŒ¨í„´ì„ êµ¬í˜„í•œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "\n",
        "agent = create_agent(llm, tools, prompt)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM ì„¤ì •\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
        "\n",
        "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
        "tools = [exa_web_search]\n",
        "\n",
        "# ì—ì´ì „íŠ¸ ìƒì„±\n",
        "langchain_agent = create_agent(llm, tools)\n",
        "\n",
        "print(\"âœ… LangChain ReAct ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "today = datetime.now().strftime(\"%Yë…„ %mì›” %dì¼\")\n",
        "\n",
        "# LangChain ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
        "test_question = \"AI ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ íŠ¸ë Œë“œë¥¼ ì•Œë ¤ì¤˜\"\n",
        "\n",
        "print(f\"ğŸ’¬ ì§ˆë¬¸: {test_question}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "for chunk in langchain_agent.stream(  \n",
        "    {\"messages\": [\n",
        "        {\"role\": \"system\", \"content\": f\"You are a helpful AI assistant with web search capabilities. Today is {today}\"},\n",
        "        {\"role\": \"user\", \"content\": test_question}]},\n",
        "    stream_mode=\"updates\"):\n",
        "    for step, data in chunk.items():\n",
        "        print(f\"step: {step}\")\n",
        "        print(f\"content: {data['messages'][-1].content_blocks}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’¡ LangChain create_agent ì •ë¦¬\n",
        "\n",
        "**ì¥ì :**\n",
        "- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì— ì í•©\n",
        "\n",
        "**í•œê³„:**\n",
        "- ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì–´ë ¤ì›€\n",
        "- ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„ ë“± ì„¸ë°€í•œ ì œì–´ ì œí•œ\n",
        "- ìƒíƒœ ê´€ë¦¬ê°€ ëª…ì‹œì ì´ì§€ ì•ŠìŒ\n",
        "\n",
        "ğŸ‘‰ **ë” ë³µì¡í•œ ì—ì´ì „íŠ¸ê°€ í•„ìš”í•˜ë‹¤ë©´? â†’ LangGraphë¡œ!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ğŸ”„ Part B: LangGraph Tool Call Routing (ì‹¬í™”)\n",
        "\n",
        "## 4. LangGraph ìƒíƒœ ì •ì˜\n",
        "\n",
        "LangGraphëŠ” **ëª…ì‹œì ì¸ ìƒíƒœ ê´€ë¦¬**ì™€ **ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "### ê·¸ë˜í”„ êµ¬ì¡°:\n",
        "```\n",
        "START â†’ call_model â†’ [tool_calls ìˆìŒ?]\n",
        "                       â”œâ”€ Yes â†’ tools â†’ call_model\n",
        "                       â””â”€ No â†’ END\n",
        "```\n",
        "\n",
        "### í•µì‹¬ ê°œë…:\n",
        "- **State**: ê·¸ë˜í”„ ì „ì²´ì—ì„œ ê³µìœ ë˜ëŠ” ìƒíƒœ\n",
        "- **Node**: ìƒíƒœë¥¼ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
        "- **Edge**: ë…¸ë“œ ê°„ ì—°ê²° (ì¡°ê±´ë¶€ ê°€ëŠ¥)\n",
        "- **ToolNode**: ë„êµ¬ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” prebuilt ë…¸ë“œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Literal\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# MessagesState: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë‚´ì¥ ìƒíƒœ\n",
        "# messages í•„ë“œê°€ ìë™ìœ¼ë¡œ ëˆ„ì ë¨\n",
        "\n",
        "print(\"ğŸ“Š MessagesState êµ¬ì¡°:\")\n",
        "print(\"  - messages: Annotated[list, add_messages]\")\n",
        "print(\"  - ë©”ì‹œì§€ê°€ ìë™ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë¨\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. ê·¸ë˜í”„ ë…¸ë“œ ë° ì—£ì§€ êµ¬í˜„\n",
        "\n",
        "ê° ë…¸ë“œì™€ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "today = datetime.now().strftime(\"%Yë…„ %mì›” %dì¼\")\n",
        "\n",
        "# LLMì— ë„êµ¬ ë°”ì¸ë”©\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# 1. ëª¨ë¸ í˜¸ì¶œ ë…¸ë“œ\n",
        "def call_model(state: MessagesState):\n",
        "    \"\"\"LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ë˜ëŠ” ë„êµ¬ í˜¸ì¶œ ê²°ì •\"\"\"\n",
        "    print(\"---CALL MODEL---\")\n",
        "    \n",
        "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"\"\"You are a helpful AI assistant with web search capabilities. Today is {today}. \n",
        "Use exa_web_search for questions requiring current information with citations. Please always respond in Korean.\"\"\"\n",
        "    }\n",
        "    \n",
        "    messages = [system_message] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    \n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# 2. ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"ë„êµ¬ í˜¸ì¶œ í•„ìš” ì—¬ë¶€ íŒë‹¨\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # tool_callsê°€ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        print(\"---ROUTING TO TOOLS---\")\n",
        "        return \"tools\"\n",
        "    \n",
        "    # ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
        "    print(\"---ROUTING TO END---\")\n",
        "    return \"__end__\"\n",
        "\n",
        "# 3. ToolNode ìƒì„± (ë„êµ¬ ì‹¤í–‰ ë‹´ë‹¹)\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "print(\"âœ… ë…¸ë“œ ë° ë¼ìš°íŒ… í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê·¸ë˜í”„ ì¡°ë¦½\n",
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "# ë…¸ë“œ ì¶”ê°€\n",
        "workflow.add_node(\"call_model\", call_model)\n",
        "workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "# ì—£ì§€ ì—°ê²°\n",
        "workflow.add_edge(START, \"call_model\")\n",
        "\n",
        "# ì¡°ê±´ë¶€ ì—£ì§€: call_model í›„ ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_model\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"__end__\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ëª¨ë¸ í˜¸ì¶œ\n",
        "workflow.add_edge(\"tools\", \"call_model\")\n",
        "\n",
        "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
        "langgraph_agent = workflow.compile()\n",
        "\n",
        "print(\"âœ… LangGraph Tool Call Routing ì—ì´ì „íŠ¸ ì»´íŒŒì¼ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê·¸ë˜í”„ ì‹œê°í™”\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(langgraph_agent.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"ì‹œê°í™” ì˜¤ë¥˜: {e}\")\n",
        "    print(\"ê·¸ë˜í”„ êµ¬ì¡°: START â†’ call_model â†’ [tools/END] â†’ call_model â†’ END\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Tool Call Routing ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
        "\n",
        "êµ¬ì¶•í•œ LangGraph ì—ì´ì „íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ëŒ€í™” (ë„êµ¬ í˜¸ì¶œ ì—†ìŒ)\n",
        "test1 = \"ì•ˆë…•í•˜ì„¸ìš”!\"\n",
        "\n",
        "print(f\"ğŸ’¬ ì§ˆë¬¸: {test1}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "result = langgraph_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": test1}]})\n",
        "print(f\"\\nğŸ¤– ë‹µë³€:\\n{result['messages'][-1].content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ 2: ì›¹ ê²€ìƒ‰ í•„ìš”í•œ ì§ˆë¬¸\n",
        "test2 = \"LangGraphì™€ CrewAIì˜ ì°¨ì´ì ì„ ì•Œë ¤ì¤˜\"\n",
        "\n",
        "print(f\"ğŸ’¬ ì§ˆë¬¸: {test2}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "result = langgraph_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": test2}]})\n",
        "print(f\"\\nğŸ¤– ë‹µë³€:\\n{result['messages'][-1].content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰ ê³¼ì • í™•ì¸\n",
        "test3 = \"OpenAIì˜ ìµœì‹  ëª¨ë¸ ì†Œì‹ì„ ì•Œë ¤ì¤˜\"\n",
        "\n",
        "print(f\"ğŸ’¬ ì§ˆë¬¸: {test3}\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nğŸ”„ ì‹¤í–‰ ê³¼ì •:\")\n",
        "\n",
        "for chunk in langgraph_agent.stream({\"messages\": [{\"role\": \"user\", \"content\": test3}]}):\n",
        "    for node_name, value in chunk.items():\n",
        "        print(f\"\\nğŸ“ [{node_name}] ë…¸ë“œ ì‹¤í–‰\")\n",
        "        \n",
        "        if \"messages\" in value and value[\"messages\"]:\n",
        "            last_msg = value[\"messages\"][-1]\n",
        "            \n",
        "            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
        "                for tc in last_msg.tool_calls:\n",
        "                    print(f\"   ğŸ”§ Tool: {tc['name']}\")\n",
        "            elif hasattr(last_msg, 'content') and last_msg.content:\n",
        "                content = str(last_msg.content)\n",
        "                if node_name == \"call_model\" and not (hasattr(last_msg, 'tool_calls') and last_msg.tool_calls):\n",
        "                    print(f\"\\nğŸ¤– ìµœì¢… ë‹µë³€:\\n{content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’¡ LangGraph Tool Call Routing ì •ë¦¬\n",
        "\n",
        "**ì¥ì :**\n",
        "- **ì™„ì „í•œ ì œì–´**: ëª¨ë“  ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì§ì ‘ ì •ì˜\n",
        "- **ìƒíƒœ ê´€ë¦¬**: ëª…ì‹œì ì¸ ìƒíƒœ ì¶”ì  ë° ë””ë²„ê¹…\n",
        "- **í™•ì¥ì„±**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°, ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„ êµ¬í˜„ ê°€ëŠ¥\n",
        "- **ì‹œê°í™”**: ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸\n",
        "\n",
        "**í•œê³„:**\n",
        "- ë” ë§ì€ ì½”ë“œ ì‘ì„± í•„ìš”\n",
        "- ê°„ë‹¨í•œ ì—ì´ì „íŠ¸ì—ëŠ” ê³¼ë„í•  ìˆ˜ ìˆìŒ\n",
        "\n",
        "ğŸ‘‰ **ë” ê°„ê²°í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´? â†’ LangGraph prebuilt create_agent!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Streaming ì‹¤ìŠµ\n",
        "\n",
        "LangGraphëŠ” ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” Stream Modes:**\n",
        "- `values`: ê° ë‹¨ê³„ í›„ ì „ì²´ ìƒíƒœ ìŠ¤íŠ¸ë¦¬ë°\n",
        "- `updates`: ê° ë‹¨ê³„ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸ë§Œ ìŠ¤íŠ¸ë¦¬ë°\n",
        "- `messages`: LLM í† í° ìŠ¤íŠ¸ë¦¬ë°\n",
        "- `custom`: ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°\n",
        "- `debug`: ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ ìŠ¤íŠ¸ë¦¬ë°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# messages ëª¨ë“œ: LLM í† í° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“Š Stream Mode: messages (LLM í† í° ìŠ¤íŠ¸ë¦¬ë°)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_query = \"OpenAIì˜ ìµœì‹  ëª¨ë¸ ì†Œì‹ì„ ì•Œë ¤ì¤˜\"\n",
        "\n",
        "print(f\"\\nğŸ’¬ ì§ˆë¬¸: {test_query}\\n\")\n",
        "print(\"ğŸ¤– ë‹µë³€: \", end=\"\", flush=True)\n",
        "\n",
        "for message_chunk, metadata in langgraph_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": test_query}]},\n",
        "    stream_mode=\"messages\"\n",
        "):\n",
        "    # LLM í† í°ë§Œ ì¶œë ¥ (tool callì€ ì œì™¸)\n",
        "    if message_chunk.content:\n",
        "        print(message_chunk.content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
